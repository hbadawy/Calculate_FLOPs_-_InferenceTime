{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from ptflops import get_model_complexity_info\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet50()\n",
        "\n",
        "flops, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
        "\n",
        "print(f\"FLOPs: {flops}, Params: {params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkZ4nAlietNU",
        "outputId": "8620eac1-7368-4ee1-c9f7-4a125d2ffd7e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 4.13 GMac, Params: 25.56 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchinfo import summary\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet50()\n",
        "\n",
        "# flops, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
        "\n",
        "input_tensor = (3, 224, 224)\n",
        "\n",
        "summary(model, input_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "qArqPuhNgyq9",
        "outputId": "4e67aae8-4f91-4010-8c27-b22ae3ca4ab7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 1]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"expected 4D input (got {input.dim()}D input)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 3D input)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-84cc9e13a04a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0;31m     summary_list = forward_pass(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mexecuted_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh1PT03Kg8xr",
        "outputId": "4ec24cec-2972-4c2d-c3a7-8ef9a85c9608"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchinfo import summary\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18()\n",
        "\n",
        "# flops, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
        "\n",
        "input_tensor = [1, 3, 224, 224]\n",
        "\n",
        "summary(model, input_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "huj-C1k-hk3t",
        "outputId": "6997f65f-1ccc-4d62-d1f9-c42878f98b3e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchinfo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-c8b0d980c5d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**summary(model, input_tensor, col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"])**"
      ],
      "metadata": {
        "id": "ufQQEfJomFt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18()\n",
        "\n",
        "# flops, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, print_per_layer_stat=False)\n",
        "\n",
        "input_tensor = [1, 3, 224, 224]\n",
        "\n",
        "summary(model, input_tensor, col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htKdG0j4ipvs",
        "outputId": "2cdd5338-68b1-4291-c148-316f2972cc41"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
              "============================================================================================================================================\n",
              "ResNet                                   [1, 3, 224, 224]          [1, 1000]                 --                        --\n",
              "├─Conv2d: 1-1                            [1, 3, 224, 224]          [1, 64, 112, 112]         9,408                     118,013,952\n",
              "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         [1, 64, 112, 112]         128                       128\n",
              "├─ReLU: 1-3                              [1, 64, 112, 112]         [1, 64, 112, 112]         --                        --\n",
              "├─MaxPool2d: 1-4                         [1, 64, 112, 112]         [1, 64, 56, 56]           --                        --\n",
              "├─Sequential: 1-5                        [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    115,605,504\n",
              "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       128\n",
              "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    115,605,504\n",
              "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       128\n",
              "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    115,605,504\n",
              "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           [1, 64, 56, 56]           128                       128\n",
              "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           [1, 64, 56, 56]           36,864                    115,605,504\n",
              "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           [1, 64, 56, 56]           128                       128\n",
              "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           [1, 64, 56, 56]           --                        --\n",
              "├─Sequential: 1-6                        [1, 64, 56, 56]           [1, 128, 28, 28]          --                        --\n",
              "│    └─BasicBlock: 2-3                   [1, 64, 56, 56]           [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-13                 [1, 64, 56, 56]           [1, 128, 28, 28]          73,728                    57,802,752\n",
              "│    │    └─BatchNorm2d: 3-14            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       256\n",
              "│    │    └─ReLU: 3-15                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-16                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-17            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       256\n",
              "│    │    └─Sequential: 3-18             [1, 64, 56, 56]           [1, 128, 28, 28]          8,448                     6,422,784\n",
              "│    │    └─ReLU: 3-19                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-20                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-21            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       256\n",
              "│    │    └─ReLU: 3-22                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "│    │    └─Conv2d: 3-23                 [1, 128, 28, 28]          [1, 128, 28, 28]          147,456                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-24            [1, 128, 28, 28]          [1, 128, 28, 28]          256                       256\n",
              "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          [1, 128, 28, 28]          --                        --\n",
              "├─Sequential: 1-7                        [1, 128, 28, 28]          [1, 256, 14, 14]          --                        --\n",
              "│    └─BasicBlock: 2-5                   [1, 128, 28, 28]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-26                 [1, 128, 28, 28]          [1, 256, 14, 14]          294,912                   57,802,752\n",
              "│    │    └─BatchNorm2d: 3-27            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       512\n",
              "│    │    └─ReLU: 3-28                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-29                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-30            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       512\n",
              "│    │    └─Sequential: 3-31             [1, 128, 28, 28]          [1, 256, 14, 14]          33,280                    6,423,040\n",
              "│    │    └─ReLU: 3-32                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    └─BasicBlock: 2-6                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-33                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-34            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       512\n",
              "│    │    └─ReLU: 3-35                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "│    │    └─Conv2d: 3-36                 [1, 256, 14, 14]          [1, 256, 14, 14]          589,824                   115,605,504\n",
              "│    │    └─BatchNorm2d: 3-37            [1, 256, 14, 14]          [1, 256, 14, 14]          512                       512\n",
              "│    │    └─ReLU: 3-38                   [1, 256, 14, 14]          [1, 256, 14, 14]          --                        --\n",
              "├─Sequential: 1-8                        [1, 256, 14, 14]          [1, 512, 7, 7]            --                        --\n",
              "│    └─BasicBlock: 2-7                   [1, 256, 14, 14]          [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-39                 [1, 256, 14, 14]          [1, 512, 7, 7]            1,179,648                 57,802,752\n",
              "│    │    └─BatchNorm2d: 3-40            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     1,024\n",
              "│    │    └─ReLU: 3-41                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-42                 [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 115,605,504\n",
              "│    │    └─BatchNorm2d: 3-43            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     1,024\n",
              "│    │    └─Sequential: 3-44             [1, 256, 14, 14]          [1, 512, 7, 7]            132,096                   6,423,552\n",
              "│    │    └─ReLU: 3-45                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    └─BasicBlock: 2-8                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-46                 [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 115,605,504\n",
              "│    │    └─BatchNorm2d: 3-47            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     1,024\n",
              "│    │    └─ReLU: 3-48                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "│    │    └─Conv2d: 3-49                 [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296                 115,605,504\n",
              "│    │    └─BatchNorm2d: 3-50            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024                     1,024\n",
              "│    │    └─ReLU: 3-51                   [1, 512, 7, 7]            [1, 512, 7, 7]            --                        --\n",
              "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 7, 7]            [1, 512, 1, 1]            --                        --\n",
              "├─Linear: 1-10                           [1, 512]                  [1, 1000]                 513,000                   513,000\n",
              "============================================================================================================================================\n",
              "Total params: 11,689,512\n",
              "Trainable params: 11,689,512\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.81\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.75\n",
              "Params size (MB): 46.76\n",
              "Estimated Total Size (MB): 87.11\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR CPU INFERENCE TIME**"
      ],
      "metadata": {
        "id": "Y1jwADrjwWMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import profiler\n",
        "\n",
        "# Example model\n",
        "model = nn.Linear(10, 1)\n",
        "\n",
        "# Dummy input\n",
        "input_tensor = torch.randn(1, 10)\n",
        "\n",
        "# Measure inference time\n",
        "with profiler.profile(record_shapes=True) as prof:\n",
        "    with profiler.record_function(\"model_inference\"):\n",
        "        output = model(input_tensor)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txIFkWvYnqwV",
        "outputId": "e0a41a2c-102c-4a77-f11a-76d4403de0ee"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "       model_inference        53.55%     156.549us       100.00%     292.330us     292.330us             1  \n",
            "          aten::linear         3.82%      11.166us        46.45%     135.781us     135.781us             1  \n",
            "           aten::addmm        17.48%      51.089us        24.76%      72.392us      72.392us             1  \n",
            "               aten::t        10.40%      30.397us        17.86%      52.223us      52.223us             1  \n",
            "       aten::transpose         5.74%      16.782us         7.47%      21.826us      21.826us             1  \n",
            "           aten::copy_         4.26%      12.455us         4.26%      12.455us      12.455us             1  \n",
            "          aten::expand         2.22%       6.486us         2.71%       7.925us       7.925us             1  \n",
            "      aten::as_strided         2.22%       6.483us         2.22%       6.483us       3.241us             2  \n",
            "    aten::resolve_conj         0.32%       0.923us         0.32%       0.923us       0.462us             2  \n",
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 292.330us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ9iISbWvjhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR GPU INFERENCE TIME**"
      ],
      "metadata": {
        "id": "RpgiwO3OwHiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import profiler\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Example model\n",
        "model = nn.Linear(10, 1).to(device)\n",
        "\n",
        "# Dummy input\n",
        "input_tensor = torch.randn(1, 10).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Measure inference time\n",
        "with profiler.profile(record_shapes=True) as prof:\n",
        "    with profiler.record_function(\"model_inference\"):\n",
        "        output = model(input_tensor)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538f78fa-b22c-47c1-856b-7061776f6c97",
        "id": "xRQe3BmSvj5W"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "     model_inference        12.60%     145.459us       100.00%       1.154ms       1.154ms             1  \n",
            "        aten::linear         1.21%      13.982us        87.40%       1.009ms       1.009ms             1  \n",
            "             aten::t         2.51%      28.947us         4.31%      49.746us      49.746us             1  \n",
            "     aten::transpose         1.41%      16.326us         1.80%      20.799us      20.799us             1  \n",
            "    aten::as_strided         0.67%       7.769us         0.67%       7.769us       3.885us             2  \n",
            "         aten::addmm        77.02%     888.970us        81.88%     945.062us     945.062us             1  \n",
            "        aten::expand         0.79%       9.075us         1.07%      12.371us      12.371us             1  \n",
            "     cudaMemcpyAsync         2.62%      30.200us         2.62%      30.200us      30.200us             1  \n",
            "    cudaLaunchKernel         1.17%      13.521us         1.17%      13.521us      13.521us             1  \n",
            "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.154ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example model\n",
        "model = nn.Linear(10, 1).to(device)\n",
        "\n",
        "# Dummy input\n",
        "input_tensor = torch.randn(1, 10).to(device)\n",
        "\n",
        "# Measure inference time\n",
        "start_event = torch.cuda.Event(enable_timing=True)\n",
        "end_event = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "start_event.record()\n",
        "output = model(input_tensor)\n",
        "end_event.record()\n",
        "\n",
        "# Waits for everything to finish running\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "inference_time = start_event.elapsed_time(end_event) / 1000  # Convert to seconds\n",
        "print(f\"Inference time: {inference_time:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9juxZ-UpxIye",
        "outputId": "2bab0562-b6aa-40fa-9ac3-2ccb9f75c3d2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 0.000396 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "device = \"cpu\" # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Example model\n",
        "model = nn.Linear(10, 1).to(device)\n",
        "\n",
        "# Dummy input\n",
        "input_tensor = torch.randn(1, 10).to(device)\n",
        "\n",
        "# Measure inference time\n",
        "start_time = time.time()\n",
        "output = model(input_tensor)\n",
        "end_time = time.time()\n",
        "\n",
        "inference_time = end_time - start_time\n",
        "print(f\"Inference time: {inference_time:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbkiJAZjxmXW",
        "outputId": "0b7c0764-b298-4c41-de30-3828fa7811df"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time: 0.000275 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = nn.Linear(10, 1).to(device)   # Example model\n",
        "input_tensor = torch.randn(1, 10).to(device)   # Dummy input\n",
        "\n",
        "\n",
        "torch.cuda.synchronize()     # Ensure any previous GPU operations are complete\n",
        "start_time = time.time()    # Measure inference time\n",
        "\n",
        "output = model(input_tensor)   # Perform the inference\n",
        "\n",
        "torch.cuda.synchronize()     # Ensure the inference is complete\n",
        "end_time = time.time()\n",
        "\n",
        "\n",
        "inference_time = end_time - start_time\n",
        "\n",
        "\n",
        "print(f\"Inference time on GPU: {inference_time:.6f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLD1O0ZIyH3e",
        "outputId": "d1aac03c-b680-4588-f5e7-3bba3a7f5e1d"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference time on GPU: 0.000474 seconds\n"
          ]
        }
      ]
    }
  ]
}